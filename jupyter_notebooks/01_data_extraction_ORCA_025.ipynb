{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e2cead0",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae96d47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import axes\n",
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "# sns.set(rc={\"figure.dpi\":200,})\n",
    "# sns.set(rc={\"figure.dpi\":300, 'savefig.dpi':300})\n",
    "sns.set_context('notebook')\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e136cb",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafa1eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_land(mask_df, data_df):\n",
    "    data_df = data_df.merge(mask_df, left_index=True, right_on=['y', 'x'])\n",
    "    data_df = data_df.loc[data_df['tmask'] == 1] ##--> comment to keep the land points\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb2a5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_nav_lat(df):\n",
    "    '''\n",
    "    Round up the coordinates to 2 decimal places\n",
    "    '''\n",
    "    df['nav_lat'] = df['nav_lat'].apply(lambda x:round(x,2))\n",
    "    df['nav_lon'] = df['nav_lon'].apply(lambda x:round(x,2))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2229a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year_month(df, yrmonth):\n",
    "    df['time_counter'] = df['time_counter'].astype(\"string\")\n",
    "    df = df.loc[df['time_counter'].str.contains(yrmonth, case=False)]\n",
    "    return df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a75a50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_over_lat_lon_yrmonth(df, yrmonth, col_name):\n",
    "    '''\n",
    "    Select a particular Month\n",
    "    Get the mean for each pair of coordinate\n",
    "    '''\n",
    "    df['time_counter'] = df['time_counter'].astype(\"string\")\n",
    "    df = df.loc[df['time_counter'].str.contains(yrmonth, case=False)]\n",
    "    df = df.groupby(['nav_lat','nav_lon'], as_index=False)[col_name].mean()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de34a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_over_lat_lon(df, col_name):\n",
    "    '''\n",
    "    Get the mean for each pair of coordinate\n",
    "    '''\n",
    "    df = df.groupby(['nav_lat','nav_lon','time_counter'], as_index=False)[col_name].mean()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53a390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_land_points(df, mask_df=None):\n",
    "\n",
    "    if mask_df is None:\n",
    "        path_mask = '../dataset/mesh_mask.nc' \n",
    "        mask = xr.open_dataset(path_mask,chunks={\"z\":1, \"y\":100, \"x\":100}).tmask.isel(z=0).squeeze()\n",
    "        mask_df = mask.to_dataframe()\n",
    "\n",
    "    df = df.merge(mask_df, left_index=True, right_on=['y', 'x'])\n",
    "    df = df.loc[sst_df['tmask'] == 1]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74441760",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "https://stackoverflow.com/questions/45122849/best-way-to-separate-range-into-n-equal-ranges-in-python \n",
    "'''\n",
    "\n",
    "def make_cells(bound_min,bound_max, cell_size):\n",
    "    step = abs(bound_min-bound_max) / cell_size\n",
    "    return [(round(step*i), round(step*(i+1))) for i in range(cell_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aebe0eb",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337e070d",
   "metadata": {},
   "source": [
    "## Data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71ca268",
   "metadata": {},
   "outputs": [],
   "source": [
    "## path for ocean model output and land mask on local machine\n",
    "\n",
    "path = '../ocean_model/output/' \n",
    "\n",
    "## OR, Load the model from HLRN\n",
    "path = \"/scratch/usr/shklvn09/SCRATCH/ORCA025.L46.LIM2vp.CFCSF6.MOPS.JRA.LP04-KLP002.hind/\"\n",
    "\n",
    "path_mask = '../ocean_model/mask/mesh_mask_orca_025.nc'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd5ab26",
   "metadata": {},
   "source": [
    "## Load mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1090cca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mask = f\"{path}/mask/mesh_mask_orca_025.nc\" \n",
    "mask = xr.open_dataset(path_mask,chunks={\"z\":1, \"y\":100, \"x\":100}).tmask.isel(z=0).squeeze()\n",
    "e1t = xr.open_dataset(path_mask,chunks={\"z\":1, \"y\":100, \"x\":100}).e1t.squeeze()\n",
    "e2t = xr.open_dataset(path_mask,chunks={\"z\":1, \"y\":100, \"x\":100}).e2t.squeeze()\n",
    "mask_df = mask.to_dataframe()\n",
    "mask_df['e1t'] = e1t.to_dataframe()['e1t']\n",
    "mask_df['e2t'] = e2t.to_dataframe()['e2t']\n",
    "mask_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b31844",
   "metadata": {},
   "source": [
    "## Load ocean model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0431ee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(1958,2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c54995",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "## Loop over 61 years\n",
    "\n",
    "for yr in years:\n",
    "    \n",
    "    print(f\"\\n---> Running {yr}\")\n",
    "    \n",
    "    ## extract SST\n",
    "    file_sst = glob(f\"{path}*sosstsst.nc\")\n",
    "    sst_xr = xr.open_dataset(file_sst[0], chunks={\"z\":1, \"y\":100, \"x\":100})\n",
    "    \n",
    "    ## extract DIC pre-ind\n",
    "    file_dicp = glob(f\"{path}*DICP_k1.nc\")\n",
    "    dicp_xr = xr.open_dataset(file_dicp[0], chunks={\"z\":1, \"y\":100, \"x\":100})\n",
    "\n",
    "    ## extract ALK\n",
    "    file_alk = glob(f\"{path}*ALK_k1.nc\")\n",
    "    alk_xr = xr.open_dataset(file_alk[0], chunks={\"z\":1, \"y\":100, \"x\":100})\n",
    "    \n",
    "    ## extract SAL\n",
    "    file_sal = glob(f\"{path}/demo/ORCA025*{yr}*sosaline*.nc\")\n",
    "    sal_xr = xr.open_dataset(file_sal[0], chunks={\"z\":1, \"y\":100, \"x\":100})\n",
    "    \n",
    "#     ## extract ice-fraction\n",
    "#     file_icemod = glob(f\"{path}/demo/ORCA025*{yr}*icemod*.nc\")\n",
    "#     icemod_xr = xr.open_dataset(file_icemod[0], chunks={\"z\":1, \"y\":100, \"x\":100}) \n",
    "    \n",
    "    ## extract mixed layer depth\n",
    "    file_mld = glob(f\"{path}/demo/ORCA025*{yr}*somxl010*.nc\")\n",
    "    mld_xr = xr.open_dataset(file_mld[0], chunks={\"z\":1, \"y\":100, \"x\":100}) \n",
    "    \n",
    "    ## extract fco2 pre-ind  \n",
    "    file_fco2 = glob(f\"{path}/demo/ORCA025*{yr}*fco2_pre.nc\")\n",
    "    fco2_xr = xr.open_dataset(file_fco2[0], chunks={\"z\":1, \"y\":100, \"x\":100})\n",
    "    \n",
    "    ## extract the variables\n",
    "    sst_df = sst_xr.sosstsst.squeeze().to_dataframe().reset_index(level=['time_counter'])\n",
    "    dicp_df = dicp_xr.DICP.squeeze().to_dataframe().reset_index(level=['time_counter'])\n",
    "    alk_df = alk_xr.ALK.squeeze().to_dataframe().reset_index(level=['time_counter'])\n",
    "    sal_df = sal_xr.sosaline.squeeze().to_dataframe().reset_index(level=['time_counter'])\n",
    "    mld_df = mld_xr.somxl010.squeeze().to_dataframe().reset_index(level=['time_counter'])\n",
    "    fco2_df = fco2_xr.fco2_pre.squeeze().to_dataframe().reset_index(level=['time_counter'])\n",
    "    \n",
    "    \n",
    "    ## apply mask\n",
    "    sst_df = sst_df.merge(mask_df, left_index=True, right_on=['y', 'x'])\n",
    "    sst_df = sst_df.loc[sst_df['tmask'] == 1]\n",
    "\n",
    "    dicp_df = dicp_df.merge(mask_df, left_index=True, right_on=['y', 'x'])\n",
    "    dicp_df = dicp_df.loc[dicp_df['tmask'] == 1]\n",
    "\n",
    "    alk_df = alk_df.merge(mask_df, left_index=True, right_on=['y', 'x'])\n",
    "    alk_df = alk_df.loc[alk_df['tmask'] == 1]\n",
    "\n",
    "    sal_df = sal_df.merge(mask_df, left_index=True, right_on=['y', 'x'])\n",
    "    sal_df = sal_df.loc[sal_df['tmask'] == 1]\n",
    "    \n",
    "    mld_df = mld_df.merge(mask_df, left_index=True, right_on=['y', 'x'])\n",
    "    mld_df = mld_df.loc[mld_df['tmask'] == 1]\n",
    "    \n",
    "    fco2_df = fco2_df.merge(mask_df, left_index=True, right_on=['y', 'x'])\n",
    "    fco2_df = fco2_df.loc[fco2_df['tmask'] == 1]\n",
    "    \n",
    "    ## put the varibales in one table\n",
    "    sosstsst_df = get_mean_over_lat_lon(df=sst_df, col_name='sosstsst')\n",
    "    e1t_df = get_mean_over_lat_lon(df=sst_df, col_name='e1t')\n",
    "    e2t_df = get_mean_over_lat_lon(df=sst_df, col_name='e2t')\n",
    "    \n",
    "    sal_df = get_mean_over_lat_lon(df=sal_df, col_name='sosaline')\n",
    "    mld_df = get_mean_over_lat_lon(df=mld_df, col_name='somxl010')\n",
    "    dicp_df = get_mean_over_lat_lon(df=dicp_df, col_name='DICP')\n",
    "    alk_df = get_mean_over_lat_lon(df=alk_df, col_name='ALK')\n",
    "    fco2_df = get_mean_over_lat_lon(df=fco2_df, col_name='fco2_pre')\n",
    "    \n",
    "    data_df = sosstsst_df.rename(columns={\"sosstsst\": \"SST\",})\n",
    "    data_df['DICP'] = dicp_df['DICP']\n",
    "    data_df['ALK'] = alk_df['ALK']\n",
    "    data_df['fco2_pre'] = fco2_df['fco2_pre']\n",
    "    data_df['SAL'] = sal_df['sosaline']\n",
    "    data_df['MLD'] = mld_df['somxl010']\n",
    "    data_df['e1t'] = e1t_df['e1t']\n",
    "    data_df['e2t'] = e2t_df['e2t']\n",
    "    \n",
    "    data_df.to_pickle(f\"../carbon_data_preprocessed/ocean_data_{yr}_df.pkl\")\n",
    "    \n",
    "    print(f\"\\n---> {yr} processed.\\n\")\n",
    "    print()\n",
    "#     time.sleep(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dend-proj",
   "language": "python",
   "name": "dend_proj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
