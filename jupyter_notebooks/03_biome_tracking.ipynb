{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24ba3b3c",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114bc66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(plt.rcParamsDefault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0c770e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting maps\n",
    "import os\n",
    "os.environ[\"PROJ_LIB\"] = os.path.join(os.environ[\"CONDA_PREFIX\"], \"share\", \"proj\")\n",
    "\n",
    "# !conda install -c conda-forge basemap\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "# # !pip install cartopy\n",
    "# import cartopy.crs as ccrs\n",
    "# import cartopy.feature as cfeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83941ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8711cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mpl_toolkits.basemap # -> install 1.3.2\n",
    "import sys\n",
    "print(mpl_toolkits.basemap.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3412b5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, LabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66148ee",
   "metadata": {},
   "source": [
    "# 2009 - Jan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787eae02",
   "metadata": {},
   "source": [
    "## Load the data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6770eb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "_year = 2009\n",
    "_month = 'jan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81843ea8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hc_df_original = pd.read_pickle(f\"output_files/clusters_spatial_regression_{_year}_{_month}.pkl\")\n",
    "hc_df_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08b2bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_df_original.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46c1b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hc_df_original['label'] = f'regime_{_year}_{_month}_' + hc_df_original['cluster'].astype(int).astype(str)\n",
    "hc_df_original['label'] = hc_df_original['cluster'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc175525",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_df_original['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121975a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65124221",
   "metadata": {},
   "source": [
    "## Prepare for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac16bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_df = hc_df_original.groupby('cell_id').mean()\n",
    "hc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572e7b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_df['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ad94fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_df['label'] = hc_df['cluster'].astype(int).astype(str)\n",
    "hc_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6631da79",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = hc_df['label'].value_counts()\n",
    "total_samples = len(hc_df)\n",
    "\n",
    "# calculate percentages\n",
    "label_percentages = label_counts / total_samples * 100\n",
    "\n",
    "# display the results\n",
    "label_stats = pd.DataFrame({'Count': label_counts, 'Percentage': label_percentages})\n",
    "label_stats.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1067f2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "regime_names_dict = {\n",
    "    1: 'ICE I',\n",
    "    2: 'ICE II',\n",
    "    3: 'SUBTR I',\n",
    "    4: 'SUBTR II',\n",
    "    6: 'SUBP + UP I',\n",
    "    7: 'SUBP + UP II',\n",
    "    5: 'SUBP + UP III',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c55a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff51d58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(hc_df['label'].unique())\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95913c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "X = hc_df[['slope_sst', 'slope_dicp', 'slope_alk']]\n",
    "y = hc_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfccc170",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa719ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.unique(y)\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c82928",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a5577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36411e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,\n",
    "                                                    shuffle=True, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42,\n",
    "                                                 shuffle=True, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130e3ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961bf98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046053de",
   "metadata": {},
   "source": [
    "# model parametertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed222f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer='adam', learning_rate=0.001):\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(64, activation='relu', kernel_regularizer=l2(0.01), input_shape=(X_train.shape[1],)),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(7, activation='softmax')  # 7 output units for 7 clusters\n",
    "    ])\n",
    "    \n",
    "    if optimizer == 'adam':\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        opt = SGD(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy', Precision(), Recall()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e0352d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter tuning\n",
    "batch_sizes = [16, 32, 64]\n",
    "optimizers = ['adam', 'sgd']\n",
    "learning_rates = [0.01, 0.001]\n",
    "epochs = [50, 100, 150, 200]\n",
    "n_splits = 5  # Number of folds for cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f39ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "for train_index, val_index in skf.split(X_train, y_train):\n",
    "    count = count + 1\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f165338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "results = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "# Initialize the label binarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "one_hot_encoded_y_test = label_binarizer.fit_transform(y_test)\n",
    "\n",
    "\n",
    "_CV = 0\n",
    "for train_index, val_index in skf.split(X_train, y_train):\n",
    "    _CV = _CV + 1\n",
    "    print(f\"_CV: {_CV}\")\n",
    "#     Fit and transform your target array\n",
    "    one_hot_encoded_y = label_binarizer.fit_transform(y_train)\n",
    "    \n",
    "    X_train_new, X_val_new = X_train[train_index], X_train[val_index]\n",
    "    one_hot_encoded_y_train, one_hot_encoded_y_val = one_hot_encoded_y[train_index], one_hot_encoded_y[val_index]\n",
    "    \n",
    "#     y_train = label_binarizer.fit_transform(y_train)\n",
    "#     y_val = label_binarizer.fit_transform(y_val)\n",
    "    \n",
    "    for batch_size in batch_sizes:\n",
    "        for optimizer in optimizers:\n",
    "            for learning_rate in learning_rates:\n",
    "                for epoch in epochs:\n",
    "                    print(f'Batch size: {batch_size}, Optimizer: {optimizer},Learning rate: {learning_rate}, Epochs: {epoch}')\n",
    "                    print()\n",
    "                    model = create_model(optimizer=optimizer, learning_rate=learning_rate)\n",
    "                    history = model.fit(X_train_new, one_hot_encoded_y_train, \n",
    "                                        epochs=epoch, batch_size=batch_size, \n",
    "                                        validation_data=(X_val_new, one_hot_encoded_y_val), verbose=0)\n",
    "\n",
    "                    test_loss, test_accuracy, test_precision, test_recall = model.evaluate(X_test, \n",
    "                                                                                           one_hot_encoded_y_test, \n",
    "                                                                                           verbose=0)\n",
    "                    results.append({'Cross Validation Iteration #':_CV,\n",
    "                                    'Batch Size': batch_size, 'Optimizer': optimizer, \n",
    "                                    'Learning Rate': learning_rate, 'Epochs': epoch,\n",
    "                                    'Test Loss': test_loss, 'Test Accuracy': test_accuracy, \n",
    "                                    'Test Precision': test_precision, 'Test Recall': test_recall})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47998104",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71bbf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_pickle(f\"output_files/parameter_tuning_2009_jan.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74185acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(f\"output_files/parameter_tuning_2009_jan.csv\", decimal='.')\n",
    "results_df.to_excel(f\"output_files/parameter_tuning_2009_jan.xlsx\", float_format='%.3f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f359f3",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fafd4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.fit_transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b10daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the label binarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "one_hot_encoded_y_train = label_binarizer.fit_transform(y_train)\n",
    "one_hot_encoded_y_val = label_binarizer.fit_transform(y_val)\n",
    "one_hot_encoded_y_test = label_binarizer.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c128e1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = models.Sequential([\n",
    "        layers.Dense(64, activation='relu', kernel_regularizer=l2(0.01), input_shape=(X_train.shape[1],)),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(7, activation='softmax')  # 7 output units for 7 clusters\n",
    "    ])\n",
    "\n",
    "learning_rate = 0.001\n",
    "opt = Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy', Precision(), Recall()])\n",
    "\n",
    "# Train the model with class weights and early stopping\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "history = model.fit(X_train_scaled, one_hot_encoded_y_train, epochs=50, batch_size=32, \n",
    "                    validation_data=(X_val_scaled, one_hot_encoded_y_val), \n",
    "#           class_weight=class_weight_dict, \n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5995bca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d221182",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mpl.rcParams['xtick.labelsize'] = 15 \n",
    "mpl.rcParams['ytick.labelsize'] = 15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6), dpi=200)\n",
    "# ax.set_facecolor('white')\n",
    "\n",
    "\n",
    "\n",
    "# Get the training and validation loss from the history object\n",
    "training_loss = history.history['loss']\n",
    "validation_loss = history.history['val_loss']\n",
    "epochs = range(1, len(training_loss) + 1)\n",
    "# Plot training and validation loss\n",
    "plt.plot(epochs, training_loss, 'b', label='Training Loss')\n",
    "plt.plot(epochs, validation_loss, 'r', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss - Categorical crossentropy', fontsize=20)\n",
    "plt.xlabel('Epochs', fontsize=20)\n",
    "plt.ylabel('Loss', fontsize=20)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6), dpi=200)\n",
    "training_acc = history.history['accuracy']\n",
    "validation_acc = history.history['val_accuracy']\n",
    "plt.plot(epochs, training_acc, 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, validation_acc, 'r', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy', fontsize=20)\n",
    "plt.xlabel('Epochs', fontsize=20)\n",
    "plt.ylabel('Accuracy', fontsize=20)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6), dpi=200)\n",
    "training_pre = history.history['precision']\n",
    "validation_pre = history.history['val_precision']\n",
    "plt.plot(epochs, training_pre, 'b', label='Training Precision')\n",
    "plt.plot(epochs, validation_pre, 'r', label='Validation Precision')\n",
    "plt.title('Training and Validation Precision', fontsize=20)\n",
    "plt.xlabel('Epochs', fontsize=20)\n",
    "plt.ylabel('Precision', fontsize=20)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6), dpi=200)\n",
    "training_recall = history.history['recall']\n",
    "validation_recall = history.history['val_recall']\n",
    "plt.plot(epochs, training_recall, 'b', label='Training Recall')\n",
    "plt.plot(epochs, validation_recall, 'r', label='Validation Recall')\n",
    "plt.title('Training and Validation Recall', fontsize=20)\n",
    "plt.xlabel('Epochs', fontsize=20)\n",
    "plt.ylabel('Recall', fontsize=20)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4e9550",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e62725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "model.evaluate(X_test_scaled, one_hot_encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d352cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(X_test_scaled)\n",
    "y_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c40220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cd230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(y_predict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae67bfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a DataFrame from y_test with the original index\n",
    "# y_test_df = pd.DataFrame(y_test, columns=label_binarizer.classes_, index=hc_df.index[X_test.index])\n",
    "\n",
    "# # Merge the y_test_df with the hc_df dataframe using the index\n",
    "# hc_df_with_predictions = hc_df.merge(y_test_df, left_index=True, right_index=True)\n",
    "\n",
    "# # hc_df_with_predictions now contains the original features and the one-hot encoded labels\n",
    "# hc_df_with_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50fd0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_encoded is the one-hot encoded ground truth\n",
    "# y_pred_encoded is the one-hot encoded predictions\n",
    "\n",
    "# Convert one-hot encoded arrays to class indices\n",
    "y_test_indices = np.argmax(one_hot_encoded_y_test, axis=1)\n",
    "y_pred_indices = np.argmax(y_predict, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(y_test_indices == y_pred_indices)\n",
    "accuracy_percentage = accuracy * 100\n",
    "\n",
    "print(f\"Accuracy: {accuracy_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b47707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e34b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the confusion matrix\n",
    "confusion = confusion_matrix(y_test_indices, y_pred_indices)\n",
    "\n",
    "# Print or display the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85249ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(confusion_matrix, class_names,vmin, vmax):\n",
    "    plt.figure(figsize=(8, 6), dpi=200)\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, \n",
    "                yticklabels=class_names, vmin=vmin, vmax=vmax)\n",
    "    plt.xlabel('Predicted Carbon Provinces', fontsize=20)\n",
    "    plt.ylabel('Original Carbon Provinces', fontsize=20,)\n",
    "    plt.title('Confusion Matrix for Model Evaluation', fontsize=20, pad=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a412e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix=confusion, class_names=class_names, \n",
    "                      vmin=0, vmax=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d6b668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# confusion matrix for 7 biomes\n",
    "conf_matrix = np.array([\n",
    "    [  5,  15,   0,   0,   2,   0,   0],\n",
    "    [  0,  91,   0,   2,   1,   0,   0],\n",
    "    [  0,   4, 757,  36,   0,   0,   5],\n",
    "    [  0,   0,   2, 504,   0,   0,   0],\n",
    "    [  0,   1,   0,   0, 299,   0,   2],\n",
    "    [  0,   0,   0,   1,   6,   0,   5],\n",
    "    [  0,   0,  18,   0,  11,   0, 378]\n",
    "])\n",
    "\n",
    "# Calculate metrics\n",
    "def calculate_metrics(conf_matrix):\n",
    "    num_classes = conf_matrix.shape[0]\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        tp = conf_matrix[i, i]\n",
    "        fn = conf_matrix[i, :].sum() - tp\n",
    "        fp = conf_matrix[:, i].sum() - tp\n",
    "        tn = conf_matrix.sum() - (tp + fn + fp)\n",
    "        \n",
    "        accuracy.append(tp / conf_matrix[i, :].sum() if conf_matrix[i, :].sum() != 0 else 0)\n",
    "        precision.append(tp / (tp + fp) if tp + fp != 0 else 0)\n",
    "        recall.append(tp / (tp + fn) if tp + fn != 0 else 0)\n",
    "\n",
    "    return accuracy, precision, recall\n",
    "\n",
    "accuracy, precision, recall = calculate_metrics(conf_matrix)\n",
    "\n",
    "labels = ['ICE I', 'ICE II','SUBTR I','SUBTR II','SUBP + UP III','SUBP + UP I','SUBP + UP II']\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.2  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 8), dpi=200)\n",
    "\n",
    "rects1 = ax.bar(x - width, accuracy, width, label='Accuracy')\n",
    "rects2 = ax.bar(x, precision, width, label='Precision')\n",
    "rects3 = ax.bar(x + width, recall, width, label='Recall')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Scores', fontsize=20)\n",
    "ax.set_title('Model evaluation: Test Accuracy, Precision, and Recall per biome', fontsize=20, pad=15)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "# Add value labels\n",
    "def add_labels(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.2f}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(8, 0),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=11, \n",
    "                    rotation=35\n",
    "                   )\n",
    "\n",
    "add_labels(rects1)\n",
    "add_labels(rects2)\n",
    "add_labels(rects3)\n",
    "\n",
    "legend_properties = {'weight':'bold', 'size':15}\n",
    "plt.legend(bbox_to_anchor=(1.18, 1.0), prop=legend_properties)\n",
    "plt.xticks(rotation=45)\n",
    "ax.tick_params(axis='x', labelsize=15)\n",
    "ax.tick_params(axis='y', labelsize=15)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4765acc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels_predicted = np.argmax(y_predict, axis=1)\n",
    "# labels_original = y_test\n",
    "# labels = range(0,8)\n",
    "# labels_predicted = [labels[i] for i in predicted_labels_argmax]\n",
    "# labels_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81503156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(y_test.values)\n",
    "# np.unique(labels_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee4fd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.sort(hc_df['label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066ecf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming y_predict is your array of predicted probabilities with shape (number_of_samples, number_of_classes)\n",
    "# Find the class with the highest probability for each sample\n",
    "# predicted_labels = np.argmax(y_predict, axis=1)\n",
    "\n",
    "# Get the selected class names based on the class indices\n",
    "# selected_class_names = [class_names[label] for label in predicted_labels]\n",
    "\n",
    "# for label in predicted_labels:\n",
    "#     print(f\"{label} --> {class_names[label]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4ab133",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(y_predict, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7028ad",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037db0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Save the entire model as a `.keras` zip archive.\n",
    "model.save('jan_2009_model_v1.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f503925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the model to a file\n",
    "model.save('tracking_model_v1')  # Save the entire model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0650e850",
   "metadata": {},
   "source": [
    "# Predict clusters "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d974a4d2",
   "metadata": {},
   "source": [
    "## Looping over multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a79d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_year = 2009\n",
    "# predict_month = 'jan'\n",
    "months = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "scaler = StandardScaler()\n",
    "class_names = ['1', '2', '3', '4', '5', '6', '7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cab49c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "loaded_model = tf.keras.models.load_model('jan_2009_model_v1.keras')\n",
    "\n",
    "for yr in range(1958, 2019): \n",
    "    \n",
    "    for month in months:\n",
    "        \n",
    "        if yr == 2009:\n",
    "            if month == 'jan':\n",
    "                continue\n",
    "                \n",
    "        print(f\"Predicting:{yr} {month}\")\n",
    "        data_new = pd.read_pickle(f\"output_files/spatial_regression_{yr}_{month}.pkl\")\n",
    "        hc_df_new = data_new.groupby('cell_id').mean()\n",
    "        X_new = hc_df_new[['slope_sst', 'slope_dicp', 'slope_alk']].dropna()\n",
    "        # Standardize features\n",
    "        X_new_scaled = scaler.fit_transform(X_new.values)\n",
    "        tarcked_labels_prob = loaded_model.predict(X_new_scaled)\n",
    "        # Find the class with the highest probability for each sample\n",
    "        tarcked_labels_indices = np.argmax(tarcked_labels_prob, axis=1)\n",
    "        # Get the selected class names based on the class indices\n",
    "        selected_regimes = [class_names[label] for label in tarcked_labels_indices]\n",
    "    \n",
    "        X_new = X_new.reset_index()\n",
    "        X_new['cluster'] = selected_regimes\n",
    "    \n",
    "        merged_df = pd.merge(X_new[['cluster', 'grid_id']], data_new, on='grid_id', how='left')\n",
    "        merged_df.to_pickle(f\"output_reg_1958_2018/adaptive_hc_clusters_{yr}_{month}.pkl\")\n",
    "        # print(merged_df)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55ed382",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dend-proj",
   "language": "python",
   "name": "dend_proj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "231px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
